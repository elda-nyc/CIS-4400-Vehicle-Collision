{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0b8bdd4e700647ba2b08c59e5df8b7da1dcf50a218bcd4c1bcd9b3dc92e8788e5",
   "display_name": "Python 3.9.4 64-bit ('3.9')"
  },
  "metadata": {
   "interpreter": {
    "hash": "b8bdd4e700647ba2b08c59e5df8b7da1dcf50a218bcd4c1bcd9b3dc92e8788e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Requirements\n",
    "- install python3.9\n",
    "- install mysql server on Mac via homebrew `brew install mysql`\n",
    "- start the mysql server `brew services start mysql`\n",
    "- install the mysql python client `pip3 install pymysql`\n",
    "- run this notebook (e.g.: VSCode's jupyter extension)\n",
    "\n",
    "# Links\n",
    "- installing python3.9: https://www.python.org/downloads/\n",
    "- installing homebrew: https://brew.sh/\n",
    "- installing VSCode and the jupyter extension: https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "source": [
    "# Open Connection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connection = pymysql.connect(\n",
    "\thost='127.0.0.1',\n",
    "\tuser='root',\n",
    "\tpassword= '',\n",
    "\tcursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#Create a database to run and store tables\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS mydatabase\")\n",
    "connection.select_db(\"mydatabase\")\n",
    "#execute a query to confirm first query worked\n",
    "cursor.execute(\"SHOW DATABASES\")\n",
    "# print(cursor.fetchall()) #Verify that mydatabase appears in the list when print statement is run"
   ]
  },
  {
   "source": [
    "# Extraction of Data from API's and CSV's"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACTION\n",
    "\n",
    "collision_data = pd.read_csv(\"https://data.cityofnewyork.us/resource/h9gi-nx95.csv\")\n",
    "features = [\"collision_id\", \"crash_time\", \"borough\", \"zip_code\", \"contributing_factor_vehicle_1\", \"contributing_factor_vehicle_2\", \"number_of_persons_injured\", \"number_of_persons_killed\",\"crash_date\"]\n",
    "collision_data = collision_data.loc[:,features]\n",
    "collision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = pd.read_csv(\"uber_nyc_enriched.csv\")  \n",
    "features = [\"pickups\", \"spd\", \"vsb\", \"temp\", \"pcp01\", \"pcp06\", \"pcp24\", \"sd\", \"borough\", \"hday\", \"pickup_dt\"]\n",
    "uber_data = uber_data.loc[:,features]\n",
    "\n",
    "uber_data.insert(0, \"uber_id\", [i for i in range(len(uber_data))])\n",
    "uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_incident_data = pd.read_csv(\"party_in_nyc.csv\")  \n",
    "features = [\"Created Date\", \"Incident Zip\", \"Borough\", \"Location Type\"]\n",
    "noise_incident_data = noise_incident_data.loc[:,features]\n",
    "\n",
    "noise_incident_data.insert(0, \"incident_id\", [i for i in range(len(noise_incident_data))])\n",
    "noise_incident_data"
   ]
  },
  {
   "source": [
    "# Transformation of Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NaN values\n",
    "collision_data.dropna(inplace=True)\n",
    "\n",
    "#Concatenate crash_time and crash_date into one column, convert to proper SQL date-time format, and drop the crash_time column\n",
    "collision_data['crash_date'] = collision_data['crash_date'].str[:10]\n",
    "collision_data['crash_date'] = collision_data['crash_date'] + ' ' +  collision_data['crash_time']\n",
    "collision_data['crash_date'] = pd.to_datetime(collision_data['crash_date'], format='%Y-%m-%d %H:%M')\n",
    "del collision_data['crash_time']\n",
    "\n",
    "#change data types\n",
    "collision_data.dtypes\n",
    "collision_data['collision_id'] = collision_data['collision_id'].astype(int)\n",
    "collision_data['borough'] = collision_data['borough'].astype(str)\n",
    "collision_data['zip_code'] = collision_data['zip_code'].astype(int)\n",
    "collision_data['contributing_factor_vehicle_1'] = collision_data['contributing_factor_vehicle_1'].astype(str)\n",
    "collision_data['contributing_factor_vehicle_2'] = collision_data['contributing_factor_vehicle_2'].astype(str)\n",
    "collision_data['number_of_persons_injured'] = collision_data['number_of_persons_injured'].astype(int)\n",
    "collision_data['number_of_persons_killed'] = collision_data['number_of_persons_killed'].astype(int)\n",
    "\n",
    "collision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary value in borough\n",
    "noise_incident_data.Borough.unique()\n",
    "noise_incident_data = noise_incident_data[noise_incident_data.Borough != 'Unspecified']\n",
    "\n",
    "#change data types\n",
    "noise_incident_data.dtypes\n",
    "noise_incident_data['incident_id'] = noise_incident_data['incident_id'].astype(int)\n",
    "noise_incident_data['Incident Zip'] = noise_incident_data['Incident Zip'].astype(float)\n",
    "noise_incident_data['Borough'] = noise_incident_data['Borough'].astype(str)\n",
    "noise_incident_data['Location Type'] = noise_incident_data['Location Type'].astype(str)\n",
    "noise_incident_data['Created Date'] = pd.to_datetime(noise_incident_data['Created Date'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_incident_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to date time\n",
    "uber_data['pickup_dt'] = pd.to_datetime(uber_data['pickup_dt'], format = '%m/%d/%y %H:%M') #1/1/15 1:00\n",
    "\n",
    "#remove NaN values\n",
    "uber_data.dropna(inplace=True)\n",
    "\n",
    "#remove unnecessary boroughs\n",
    "uber_data.borough.unique()\n",
    "uber_data = uber_data[uber_data.borough != 'EWR']\n",
    "\n",
    "#match borough text with other dataframes\n",
    "uber_data['borough'] = uber_data['borough'].str.upper()\n",
    "\n",
    "#change data types\n",
    "uber_data.dtypes\n",
    "uber_data['uber_id'] = uber_data['uber_id'].astype(int)\n",
    "uber_data['pickups'] = uber_data['pickups'].astype(int)\n",
    "uber_data['borough'] = uber_data['borough'].astype(str)\n",
    "uber_data['hday'] = uber_data['hday'].astype(str)\n",
    "uber_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data"
   ]
  },
  {
   "source": [
    "## Creating the fact dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### define the size of the dataframe to be the smallest size between all the referenced tables so that there are no missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table_size = min(\n",
    "    len(collision_data),\n",
    "    len(uber_data),\n",
    "    len(noise_incident_data)\n",
    ")"
   ]
  },
  {
   "source": [
    "### create table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = pd.DataFrame(data=uber_data['uber_id'])\n",
    "facts.insert(1,'collision_id',collision_data['collision_id'])\n",
    "facts.insert(2,'incident_id',noise_incident_data['incident_id'])\n",
    "facts = facts.loc[:fact_table_size]\n",
    "facts"
   ]
  }
 ]
}